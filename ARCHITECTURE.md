# üèóÔ∏è MEDORBY ‚Äî System Architecture & Implementation

> Technical deep-dive into how MEDORBY is built, the design decisions behind each component, and the end-to-end data flow.

---

## Table of Contents

1. [High-Level Architecture](#1-high-level-architecture)
2. [Data Flow Pipeline](#2-data-flow-pipeline)
3. [Backend Architecture](#3-backend-architecture)
4. [Frontend Architecture](#4-frontend-architecture)
5. [Council Protocol Design](#5-council-protocol-design)
6. [RAG System Design](#6-rag-system-design)
7. [ML Pipeline Design](#7-ml-pipeline-design)
8. [Storage Architecture](#8-storage-architecture)
9. [Privacy Architecture](#9-privacy-architecture)
10. [Federated Learning Architecture](#10-federated-learning-architecture)
11. [API Design](#11-api-design)
12. [Deployment Guide](#12-deployment-guide)
13. [Design Decisions & Trade-offs](#13-design-decisions--trade-offs)

---

## 1. High-Level Architecture

MEDORBY follows a **"Local-First, Cloud-Consensus"** architecture. Sensitive operations run locally; only sanitised data reaches cloud LLMs for clinical reasoning.

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        EDGE (User's Device)                            ‚îÇ
‚îÇ                                                                         ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ Browser   ‚îÇ  ‚îÇ PII          ‚îÇ  ‚îÇ Encrypted      ‚îÇ  ‚îÇ Federated  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ (Next.js) ‚îÇ  ‚îÇ Sanitizer    ‚îÇ  ‚îÇ IndexedDB      ‚îÇ  ‚îÇ Learning   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ (client-side)‚îÇ  ‚îÇ (AES-256-GCM)  ‚îÇ  ‚îÇ Client     ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ        ‚îÇ               ‚îÇ                                      ‚îÇ        ‚îÇ
‚îÇ        ‚îÇ    Sanitised   ‚îÇ                        DP-noised     ‚îÇ        ‚îÇ
‚îÇ        ‚îÇ    Prompt      ‚îÇ                        Gradients     ‚îÇ        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ               ‚îÇ                                      ‚îÇ
         ‚ñº               ‚ñº                                      ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     SERVER (FastAPI Backend)                             ‚îÇ
‚îÇ                                                                         ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îÇ
‚îÇ  ‚îÇ Red-Flag ‚îÇ  ‚îÇ ML       ‚îÇ  ‚îÇ RAG      ‚îÇ  ‚îÇ Hospital ‚îÇ  ‚îÇ FedAvg   ‚îÇ‚îÇ
‚îÇ  ‚îÇ Engine   ‚îÇ  ‚îÇ Classifier‚îÇ  ‚îÇ Engine   ‚îÇ  ‚îÇ DB       ‚îÇ  ‚îÇAggregator‚îÇ‚îÇ
‚îÇ  ‚îÇ (core/)  ‚îÇ  ‚îÇ (ml/)    ‚îÇ  ‚îÇ (rag/)   ‚îÇ  ‚îÇ(storage/)‚îÇ  ‚îÇ(federated‚îÇ|
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ
‚îÇ       ‚îÇ              ‚îÇ              ‚îÇ              ‚îÇ                    ‚îÇ
‚îÇ       ‚ñº              ‚ñº              ‚ñº              ‚îÇ                    ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ                    ‚îÇ
‚îÇ  ‚îÇ         Council Orchestrator              ‚îÇ     ‚îÇ                    ‚îÇ
‚îÇ  ‚îÇ         (council/)                        ‚îÇ     ‚îÇ                    ‚îÇ
‚îÇ  ‚îÇ                                           ‚îÇ     ‚îÇ                    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ     ‚îÇ                    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇMember A ‚îÇ ‚îÇMember B ‚îÇ ‚îÇMember C ‚îÇ    ‚îÇ     ‚îÇ                    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇLlama 70B‚îÇ ‚îÇLlama 8B ‚îÇ ‚îÇQwen3 32B‚îÇ    ‚îÇ     ‚îÇ                    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ     ‚îÇ                    ‚îÇ
‚îÇ  ‚îÇ       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îÇ     ‚îÇ                    ‚îÇ
‚îÇ  ‚îÇ                   ‚ñº                      ‚îÇ     ‚îÇ                    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îÇ     ‚îÇ                    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Reviewer ‚Üí Chairman          ‚îÇ        ‚îÇ     ‚îÇ                    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ (Peer Review ‚Üí Synthesis)    ‚îÇ        ‚îÇ     ‚îÇ                    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îÇ     ‚îÇ                    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ                    ‚îÇ
‚îÇ                     ‚îÇ                              ‚îÇ                    ‚îÇ
‚îÇ                     ‚ñº                              ‚ñº                    ‚îÇ
‚îÇ              SSE Stream ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ Store Anonymised Record         ‚îÇ
‚îÇ                     ‚îÇ                                                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                      ‚îÇ
                      ‚ñº
               ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
               ‚îÇ  Browser UI  ‚îÇ
               ‚îÇ  (Real-time) ‚îÇ
               ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Architectural Principles

| Principle | Implementation |
|-----------|---------------|
| **Privacy by Design** | PII never leaves the browser; all storage encrypted |
| **Local-First** | Emergency detection, classification, and storage run locally |
| **Cloud-Consensus** | Only sanitised prompts reach cloud LLMs; multiple models cross-verify |
| **Fail-Safe** | If any model fails, the pipeline continues with fallback data |
| **Modular** | Each subsystem is an independent Python package with clear interfaces |
| **Observable** | SSE streaming gives real-time visibility into every pipeline stage |

---

## 2. Data Flow Pipeline

The complete request lifecycle from user input to displayed results:

```
Step 1: USER INPUT
  ‚îÇ  Symptoms + optional vitals + optional age/sex
  ‚îÇ
  ‚ñº
Step 2: PII SANITIZATION (Client-Side ‚Äî sanitizer.ts)
  ‚îÇ  Regex-based removal of names, emails, phones, dates
  ‚îÇ  Output: sanitised_prompt (safe to send over network)
  ‚îÇ
  ‚ñº
Step 3: RED-FLAG TRIAGE (Server ‚Äî core/red_flag_engine.py)
  ‚îÇ  Deterministic vital sign checks + keyword matching
  ‚îÇ  If EMERGENCY ‚Üí return immediately (no LLM calls)
  ‚îÇ  If SAFE ‚Üí continue to Step 4
  ‚îÇ
  ‚ñº
Step 4: LOCAL ML CLASSIFICATION (Server ‚Äî ml/symptom_classifier.py)
  ‚îÇ  TF-IDF vectorisation ‚Üí Logistic Regression prediction
  ‚îÇ  Output: category, severity, confidence
  ‚îÇ  Streamed to frontend via SSE
  ‚îÇ
  ‚ñº
Step 5: RAG CONTEXT RETRIEVAL (Server ‚Äî rag/engine.py)
  ‚îÇ  TF-IDF vectorise query ‚Üí FAISS similarity search
  ‚îÇ  Top-K relevant documents from knowledge base + user reports
  ‚îÇ  Output: context string appended to prompt
  ‚îÇ  Streamed to frontend via SSE
  ‚îÇ
  ‚ñº
Step 6: COUNCIL DELIBERATION (Server ‚Äî council/orchestrator.py)
  ‚îÇ
  ‚îÇ  6a. DIVERGENCE ‚Äî 3 models reason in parallel
  ‚îÇ      Augmented prompt (symptoms + RAG context) sent to:
  ‚îÇ      - Member A (Llama 3.3 70B)
  ‚îÇ      - Member B (Llama 3.1 8B)
  ‚îÇ      - Member C (Qwen3 32B)
  ‚îÇ
  ‚îÇ  6b. CONVERGENCE ‚Äî Reviewer ranks responses
  ‚îÇ      Compact summaries sent to Reviewer (Llama 8B)
  ‚îÇ      Output: ranking [A, B, C] + reasoning
  ‚îÇ
  ‚îÇ  6c. SYNTHESIS ‚Äî Chairman produces final answer
  ‚îÇ      Top-ranked response + ranking sent to Chairman (Llama 70B)
  ‚îÇ      Output: final_differentials, recommended_next_steps,
  ‚îÇ              confidence, red_flag, summary
  ‚îÇ
  ‚ñº
Step 7: POST-PROCESSING (Server ‚Äî storage/hospital_db.py)
  ‚îÇ  Anonymised consultation record stored in SQLite
  ‚îÇ  Symptom hash (SHA-256), not raw text
  ‚îÇ
  ‚ñº
Step 8: DISPLAY (Frontend ‚Äî ChatInterface.tsx)
  ‚îÇ  Classification card, RAG context, council consensus
  ‚îÇ  Individual member responses (expandable)
  ‚îÇ
  ‚ñº
Step 9: FEEDBACK (Optional)
     User provides thumbs-up/thumbs-down
     ‚Üí DP-noised gradient ‚Üí Federated aggregator
```

---

## 3. Backend Architecture

### Module Structure

```
backend/
‚îú‚îÄ‚îÄ main.py              ‚Üê FastAPI entry point, all route definitions
‚îú‚îÄ‚îÄ config.py            ‚Üê Pydantic BaseSettings (.env loader)
‚îÇ
‚îú‚îÄ‚îÄ core/                ‚Üê Core utilities (no external API calls)
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ red_flag_engine.py
‚îÇ
‚îú‚îÄ‚îÄ council/             ‚Üê LLM Council (Groq API)
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ groq_client.py   ‚Üê AsyncGroq client, model config, parallel queries
‚îÇ   ‚îî‚îÄ‚îÄ orchestrator.py  ‚Üê 3-stage protocol: diverge ‚Üí converge ‚Üí synthesise
‚îÇ
‚îú‚îÄ‚îÄ ml/                  ‚Üê Machine Learning (local, no API)
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ symptom_classifier.py  ‚Üê TF-IDF + Logistic Regression classifier
‚îÇ
‚îú‚îÄ‚îÄ rag/                 ‚Üê Retrieval-Augmented Generation (local)
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ engine.py        ‚Üê FAISS index + TF-IDF vectoriser + retrieval
‚îÇ   ‚îî‚îÄ‚îÄ report_processor.py  ‚Üê PDF/DOCX/TXT text extraction + storage
‚îÇ
‚îú‚îÄ‚îÄ storage/             ‚Üê Persistent storage (local SQLite)
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ hospital_db.py   ‚Üê Schema, CRUD operations, stats
‚îÇ
‚îî‚îÄ‚îÄ federated/           ‚Üê Federated Learning
    ‚îú‚îÄ‚îÄ __init__.py
    ‚îú‚îÄ‚îÄ aggregator.py    ‚Üê FedAvg aggregation, client management
    ‚îî‚îÄ‚îÄ dp_privacy.py    ‚Üê Gradient clipping + Gaussian noise injection
```

### Key Design Decisions

1. **Flat `main.py`**: All routes in one file for simplicity. Each route delegates to the appropriate module.
2. **Module `__init__.py` exports**: Each package exports its public API, so `main.py` imports are clean.
3. **No ORM**: Raw SQLite for the hospital DB ‚Äî simpler, fewer dependencies, better performance for this use case.
4. **Singleton patterns**: `get_rag_engine()`, `get_classifier()`, and `get_settings()` use caching/singletons to avoid re-initialisation.

### Dependency Graph

```
main.py
  ‚îú‚îÄ‚îÄ config.py (settings)
  ‚îú‚îÄ‚îÄ core/red_flag_engine.py (no deps)
  ‚îú‚îÄ‚îÄ council/
  ‚îÇ   ‚îú‚îÄ‚îÄ groq_client.py ‚Üê config.py
  ‚îÇ   ‚îî‚îÄ‚îÄ orchestrator.py ‚Üê groq_client.py
  ‚îú‚îÄ‚îÄ ml/symptom_classifier.py (sklearn, numpy)
  ‚îú‚îÄ‚îÄ rag/
  ‚îÇ   ‚îú‚îÄ‚îÄ engine.py (faiss, sklearn)
  ‚îÇ   ‚îî‚îÄ‚îÄ report_processor.py (PyPDF2, python-docx)
  ‚îú‚îÄ‚îÄ storage/hospital_db.py (sqlite3)
  ‚îî‚îÄ‚îÄ federated/
      ‚îú‚îÄ‚îÄ aggregator.py (numpy)
      ‚îî‚îÄ‚îÄ dp_privacy.py (numpy)
```

---

## 4. Frontend Architecture

### Component Hierarchy

```
app/layout.tsx                 ‚Üê Root layout (fonts, meta tags)
  ‚îî‚îÄ‚îÄ app/page.tsx             ‚Üê Landing page
        ‚îú‚îÄ‚îÄ Hero Section       ‚Üê Title, CTA, animated stats
        ‚îú‚îÄ‚îÄ Pipeline Section   ‚Üê 5-step visual pipeline
        ‚îú‚îÄ‚îÄ Features Grid      ‚Üê 9 feature cards
        ‚îú‚îÄ‚îÄ Council Grid       ‚Üê 5 AI member cards
        ‚îú‚îÄ‚îÄ ChatInterface.tsx  ‚Üê Main consultation component
        ‚îÇ     ‚îú‚îÄ‚îÄ Report Upload Panel
        ‚îÇ     ‚îú‚îÄ‚îÄ Demographics Form
        ‚îÇ     ‚îú‚îÄ‚îÄ Vitals Form
        ‚îÇ     ‚îú‚îÄ‚îÄ Symptoms Textarea
        ‚îÇ     ‚îú‚îÄ‚îÄ Classification Card
        ‚îÇ     ‚îú‚îÄ‚îÄ RAG Context Card
        ‚îÇ     ‚îú‚îÄ‚îÄ Stage Progress Bar
        ‚îÇ     ‚îú‚îÄ‚îÄ Consensus Result Card
        ‚îÇ     ‚îú‚îÄ‚îÄ Member Tabs (expandable)
        ‚îÇ     ‚îî‚îÄ‚îÄ Feedback Buttons
        ‚îî‚îÄ‚îÄ Footer             ‚Üê Tech stack badges, disclaimer
```

### Frontend Libraries

| Library | Version | Purpose |
|---------|---------|---------|
| Next.js | 16.1.6 | React framework (App Router) |
| React | 19.2.3 | UI library |
| Lucide React | 0.574+ | Icon library |
| Vanilla CSS | ‚Äî | Full design system (no Tailwind) |

### Design System

The CSS is organised in `globals.css` using BEM-like naming:

```css
/* Block */
.result-card { ... }

/* Element */
.result-card__header { ... }
.result-card__title { ... }

/* Modifier */
.stage-item--running { ... }
.stage-item--complete { ... }
```

Key design tokens:
- **Background**: `#020617` (near-black) with glassmorphism overlays
- **Primary**: `#3b82f6` (blue), `#10b981` (green), `#8b5cf6` (violet)
- **Typography**: Inter (Google Fonts) system stack
- **Animations**: CSS keyframes for fade-in, pulse, spin

---

## 5. Council Protocol Design

### Why a Multi-Model Council?

Single-model medical AI has inherent limitations:
- **Hallucination risk**: One model may confidently assert incorrect diagnoses
- **Training bias**: Each model has different training data coverage
- **No cross-verification**: A single model can't catch its own errors

The council approach solves these by:
- **Diversity**: 3 different model architectures (Llama 70B, Llama 8B, Qwen3 32B)
- **Peer Review**: Independent ranking catches outlier/hallucinated responses
- **Consensus**: Chairman synthesises only the top-ranked reasoning

### Stage Details

#### Divergence (Parallel Fan-Out)

```python
# council/groq_client.py
async def query_council_parallel(sanitized_prompt: str) -> dict[str, str]:
    tasks = {
        name: query_groq(model, [system_msg, user_msg])
        for name, model in COUNCIL_MODELS.items()
        if name in ("member_a", "member_b", "member_c")
    }
    results = await asyncio.gather(*tasks.values(), return_exceptions=True)
```

- All 3 models run **simultaneously** via `asyncio.gather`
- Each returns structured JSON: `{differentials, next_steps, confidence, red_flag}`
- Exceptions are caught and replaced with fallback JSON

#### Convergence (Peer Review)

```python
# council/orchestrator.py ‚Äî Compact prompt design
summary_lines = "\n".join(
    f"  {anon_map[m]}: {_summarise_response(divergence_results[m])}"
    for m in members
)
```

- Member responses are **anonymised** (A, B, C) to prevent model bias
- Only **compact summaries** are sent (not full JSON), reducing latency
- Reviewer model outputs a ranking + brief reasoning

#### Synthesis (Chairman)

- Only the **top-ranked** member's full response is sent to the Chairman
- Chairman produces: `final_differentials`, `recommended_next_steps`, `confidence`, `summary`
- Temperature is set to **0.2** for deterministic, focused output

---

## 6. RAG System Design

### Indexing Pipeline

```
Knowledge Base JSON ‚îÄ‚îÄ‚îê
                      ‚îú‚îÄ‚îÄ‚ñ∫ TF-IDF Vectoriser ‚îÄ‚îÄ‚ñ∫ FAISS IndexFlatIP
User Report Text ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        (4096-dim)
```

### Retrieval Pipeline

```
Query Text ‚îÄ‚îÄ‚ñ∫ TF-IDF Transform ‚îÄ‚îÄ‚ñ∫ FAISS Search ‚îÄ‚îÄ‚ñ∫ Top-K Results
                                                          ‚îÇ
                                                          ‚ñº
                                                    Context String
                                                    (appended to LLM prompt)
```

### Technical Details

| Component | Choice | Rationale |
|-----------|--------|-----------|
| **Vectoriser** | TF-IDF (4096-dim) | Fast, no GPU required, good for medical vocabulary |
| **Index** | FAISS `IndexFlatIP` | Exact inner product search, optimal for small corpora |
| **Similarity** | Cosine (via L2-normalised IP) | Standard for text retrieval |
| **Fallback** | TF-IDF (not sentence-transformers) | `sentence-transformers` has import issues; TF-IDF is reliable |

### Why TF-IDF Instead of Dense Embeddings?

Dense embeddings (e.g., from `sentence-transformers`) are generally better for semantic search. However:
1. **Dependency issues**: `sentence-transformers` has known import failures in some environments
2. **Speed**: TF-IDF index builds in milliseconds vs. minutes for dense models
3. **Medical vocabulary**: TF-IDF naturally handles medical terminology without needing fine-tuned embeddings
4. **Future upgrade path**: The RAG engine is architected to swap in dense embeddings when available

---

## 7. ML Pipeline Design

### Training Data

The classifier is pre-trained at startup using 64 curated examples across 5 categories:

```python
# ml/symptom_classifier.py
TRAINING_DATA = [
    ("crushing chest pain radiating to left arm sweating nausea", "cardiac_emergency"),
    ("persistent fatigue swollen ankles difficulty breathing when lying down", "cardiac_chronic"),
    ("heart skipping beats irregular pulse dizziness lightheaded", "cardiac_arrhythmia"),
    # ... 64 total examples
]
```

### Model Architecture

```
Input Text ‚Üí TfidfVectorizer(max_features=4096) ‚Üí LogisticRegression(C=1.0, multinomial)
                                                         ‚îÇ
                                                         ‚ñº
                                                  {category, severity, confidence,
                                                   description, action, probabilities}
```

### Why Logistic Regression?

| Factor | Logistic Regression | Deep Learning |
|--------|-------------------|---------------|
| **Training time** | ~50ms | Minutes to hours |
| **Inference time** | <1ms | 10-100ms |
| **Data needed** | ~60 examples | 1000s+ examples |
| **Interpretability** | High (coefficients) | Low (black box) |
| **GPU required** | No | Yes |
| **Accuracy (for this task)** | Good enough for triage routing | Marginal improvement |

The classifier's role is triage routing, not final diagnosis ‚Äî the LLM council provides the detailed clinical reasoning.

---

## 8. Storage Architecture

### Dual-Storage Strategy

| Storage | Location | Encryption | Contents |
|---------|----------|------------|----------|
| **IndexedDB** | Browser | AES-256-GCM | Consultation history, preferences |
| **SQLite** | Server (`data/`) | None (local file) | Anonymised medical records, federated contributions |
| **File System** | Server (`user_reports/`) | None (local file) | Uploaded medical reports |
| **FAISS Index** | Server (`faiss_index/`) | None (memory/disk) | Vector index for RAG retrieval |

### SQLite Schema

```sql
-- Anonymised consultation records
CREATE TABLE medical_records (
    id TEXT PRIMARY KEY,
    record_type TEXT NOT NULL,        -- 'consultation' | 'report'
    category TEXT,                     -- from classifier
    severity TEXT,                     -- 'critical' | 'moderate' | 'low'
    symptoms_hash TEXT,                -- SHA-256 hash (never raw text)
    council_summary TEXT,              -- anonymised council output
    confidence REAL,
    timestamp TEXT NOT NULL,
    metadata TEXT                      -- JSON for extension fields
);

-- Federated learning audit trail
CREATE TABLE federated_contributions (
    id TEXT PRIMARY KEY,
    record_id TEXT,
    gradient_hash TEXT,
    dp_noise_level REAL,
    contributed_at TEXT NOT NULL,
    aggregation_round INTEGER,
    status TEXT DEFAULT 'pending'      -- 'pending' | 'aggregated'
);
```

---

## 9. Privacy Architecture

### Privacy Layers

```
Layer 1: CLIENT-SIDE PII SANITISATION
  ‚îú‚îÄ‚îÄ Regex removal of names, emails, phones, dates, IDs
  ‚îú‚îÄ‚îÄ Runs entirely in the browser (sanitizer.ts)
  ‚îî‚îÄ‚îÄ Zero PII reaches the network

Layer 2: DETERMINISTIC TRIAGE
  ‚îú‚îÄ‚îÄ Red-Flag Engine uses rule-based logic (no ML/LLM)
  ‚îú‚îÄ‚îÄ Emergency detection requires zero cloud calls
  ‚îî‚îÄ‚îÄ Auditable, reproducible, explainable

Layer 3: LOCAL ML CLASSIFICATION
  ‚îú‚îÄ‚îÄ TF-IDF + LogReg runs on the server (no cloud ML)
  ‚îú‚îÄ‚îÄ No training data leaves the device
  ‚îî‚îÄ‚îÄ Classification informs but doesn't replace LLM

Layer 4: ANONYMISED STORAGE
  ‚îú‚îÄ‚îÄ SHA-256 symptom hashes (not raw text) in SQLite
  ‚îú‚îÄ‚îÄ AES-256-GCM encrypted local history in browser
  ‚îî‚îÄ‚îÄ Uploaded reports never transmitted anywhere

Layer 5: DIFFERENTIAL PRIVACY (Federated Learning)
  ‚îú‚îÄ‚îÄ L2 gradient clipping (bound sensitivity)
  ‚îú‚îÄ‚îÄ Gaussian noise injection (œÉ = 1.1)
  ‚îú‚îÄ‚îÄ Only aggregate after 3+ client updates
  ‚îî‚îÄ‚îÄ Formal (Œµ, Œ¥)-differential privacy guarantee
```

### Threat Model

| Threat | Mitigation |
|--------|------------|
| Cloud provider reads medical data | PII stripped client-side; only sanitised prompts sent |
| Network eavesdropper | HTTPS + no PII in transit |
| Local device theft | IndexedDB encrypted with AES-256-GCM |
| Model update reveals data | Differential privacy noise on all gradients |
| Server compromise | SQLite contains only hashes, not raw symptoms |

---

## 10. Federated Learning Architecture

### FedAvg Protocol

```
Client 1 ‚îÄ‚îÄ‚ñ∫ DP(‚àáŒ∏‚ÇÅ) ‚îÄ‚îÄ‚îê
                         ‚îÇ
Client 2 ‚îÄ‚îÄ‚ñ∫ DP(‚àáŒ∏‚ÇÇ) ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚ñ∫ Aggregator ‚îÄ‚îÄ‚ñ∫ Œ∏_global = Œ£(DP(‚àáŒ∏·µ¢)) / N
                         ‚îÇ
Client 3 ‚îÄ‚îÄ‚ñ∫ DP(‚àáŒ∏‚ÇÉ) ‚îÄ‚îÄ‚îò
```

### Implementation Flow

1. **User Feedback**: Thumbs-up or thumbs-down on council output
2. **Pseudo-Gradient**: `local_learning.ts` computes a gradient-like vector from the feedback text
3. **DP Noise**: Gradient is clipped (L2 norm) and Gaussian noise is added client-side
4. **Submission**: Noised gradient sent to `POST /api/federated/update`
5. **Aggregation**: Server buffers updates; FedAvg runs when ‚â•3 clients have submitted
6. **Distribution**: Updated adapter available at `GET /api/federated/adapter`

### Privacy Budget

| Parameter | Value | Meaning |
|-----------|-------|---------|
| Clip norm (C) | 1.0 | Maximum L2 norm of any single gradient |
| Noise multiplier (œÉ) | 1.1 | Gaussian noise std relative to clip norm |
| Min clients (K) | 3 | Minimum updates before aggregation |
| Privacy (Œµ) | ~2-3 | Per-round privacy budget (approximate) |

---

## 11. API Design

### REST Conventions

- All endpoints use JSON request/response bodies
- SSE streaming for long-running council deliberations
- Standard HTTP status codes (200, 400, 404, 500)
- CORS configured for `localhost:3000` (frontend)

### Request Models

```python
class SymptomRequest(BaseModel):
    sanitized_prompt: str          # PII-free text from sanitizer.ts
    vitals: Optional[dict] = None  # {heart_rate, spo2, systolic_bp}

class FederatedUpdateRequest(BaseModel):
    client_id: str                 # Unique client identifier
    gradients: list[float]         # DP-noised adapter delta
```

### SSE Event Format

```json
{"stage": "classification", "status": "complete", "data": {...}}
{"stage": "rag_retrieval", "status": "complete", "data": {...}}
{"stage": "divergence", "status": "running"}
{"stage": "divergence", "status": "complete", "data": {...}}
{"stage": "convergence", "status": "running"}
{"stage": "convergence", "status": "complete", "data": {...}}
{"stage": "synthesis", "status": "running"}
{"stage": "synthesis", "status": "complete", "data": {...}}
{"stage": "done"}
```

---

## 12. Deployment Guide

### Development (Local)

```bash
# Terminal 1: Backend
cd backend
python -m venv venv
.\venv\Scripts\activate
pip install -r requirements.txt
cp .env.example .env  # Add your GROQ_API_KEY
uvicorn main:app --reload --port 8000

# Terminal 2: Frontend
cd frontend
npm install
npm run dev
# ‚Üí http://localhost:3000
```

### Environment Variables

#### Backend (`backend/.env`)

| Variable | Required | Default | Description |
|----------|----------|---------|-------------|
| `GROQ_API_KEY` | ‚úÖ Yes | ‚Äî | Groq Cloud API key |
| `VLLM_BASE_URL` | No | `http://localhost:8001/v1` | vLLM endpoint (if using) |
| `VLLM_MODEL_NAME` | No | `meta-llama/Llama-3-8B-Instruct` | vLLM model (if using) |
| `FEDERATED_SECRET_KEY` | No | `change_this_secret_key` | Secret for federated auth |

#### Frontend (`frontend/.env.local`)

| Variable | Required | Default | Description |
|----------|----------|---------|-------------|
| `NEXT_PUBLIC_BACKEND_URL` | No | `http://localhost:8000` | Backend API URL |

### Production Considerations

| Concern | Recommendation |
|---------|----------------|
| **HTTPS** | Use a reverse proxy (nginx) with Let's Encrypt |
| **CORS** | Restrict `allow_origins` to your production domain |
| **Rate Limiting** | Add API rate limiting (e.g., `slowapi`) |
| **Monitoring** | Add structured logging + metrics (Prometheus/Grafana) |
| **Database** | Consider PostgreSQL for production hospital DB |
| **Secrets** | Use proper secret management (HashiCorp Vault, AWS Secrets Manager) |

---

## 13. Design Decisions & Trade-offs

### Why Groq Cloud Instead of Self-Hosted?

| Factor | Groq Cloud | Self-Hosted (vLLM) |
|--------|-----------|-------------------|
| **Latency** | ~200ms per model call | 2-5s per model call |
| **Cost** | Free tier available | GPU hardware costs |
| **Privacy** | Sanitised data only | Full control |
| **Reliability** | 99.9% uptime | Self-managed |
| **Setup** | API key only | GPU setup, model download |

**Decision**: Use Groq for speed and accessibility. PII sanitization ensures privacy despite cloud calls.

### Why 3 Models Instead of 1 or 5?

- **1 model**: No error checking, hallucination risk
- **3 models**: Optimal diversity-to-latency ratio; majority voting is meaningful
- **5+ models**: Diminishing returns; latency increases; cost multiplies

### Why TF-IDF Instead of Dense Embeddings for RAG?

- **Reliability**: TF-IDF has zero dependency issues
- **Speed**: Index builds in milliseconds
- **Medical domain**: Term-level matching works well for medical queries
- **Upgrade path**: Architecture supports swapping to dense embeddings later

### Why SQLite Instead of PostgreSQL?

- **Local-first**: No server setup required
- **Privacy**: Data stays in a local file, not a network database
- **Simplicity**: Zero configuration, zero maintenance
- **Portability**: Database is a single file that moves with the project

### Why SSE Instead of WebSockets?

- **Simplicity**: One-directional stream is sufficient (server ‚Üí client)
- **Compatibility**: Works with standard HTTP; no upgrade handshake needed
- **Resilience**: Automatic reconnection built into browser `EventSource` API
- **Fetch API**: Can be consumed with standard `fetch` + `ReadableStream`

---

<p align="center">
  üìñ See <a href="FEATURES.md">FEATURES.md</a> for detailed feature documentation.<br>
  üìñ See <a href="README.md">README.md</a> for setup instructions.
</p>
